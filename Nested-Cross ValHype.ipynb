{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_boost(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "        # https://conference.scipy.org/proceedings/scipy2013/pdfs/bergstra_hyperopt.pdf\n",
    "    from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "    space = {\n",
    "        'max_depth' : hp.choice('max_depth', range(5, 30, 1)),\n",
    "        'learning_rate' : hp.quniform('learning_rate', 0.01, 0.5, 0.01),\n",
    "        'n_estimators' : hp.choice('n_estimators', range(20, 205, 5)),\n",
    "        'gamma' : hp.quniform('gamma', 0, 0.50, 0.01),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 1, 10, 1),\n",
    "        'subsample' : hp.quniform('subsample', 0.1, 1, 0.01),\n",
    "        'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1.0, 0.01)}\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    def objective(space):\n",
    "        \n",
    "        classifier = xgb.XGBClassifier(n_estimators = space['n_estimators'],\n",
    "                                max_depth = int(space['max_depth']),\n",
    "                                learning_rate = space['learning_rate'],\n",
    "                                gamma = space['gamma'],\n",
    "                                min_child_weight = space['min_child_weight'],\n",
    "                                subsample = space['subsample'],\n",
    "                                colsample_bytree = space['colsample_bytree']\n",
    "                                )\n",
    "\n",
    "        classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Applying k-Fold Cross Validation\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "        CrossValMean = accuracies.mean()\n",
    "        CrossValVar = accuracies.var()\n",
    "        \n",
    "        print(\"CrossValMean:\", CrossValMean)\n",
    "        print(\"CrossValVar:\", CrossValVar)\n",
    "\n",
    "        return{'loss':1-CrossValMean, 'status': STATUS_OK }\n",
    "\n",
    "\n",
    "    ###################################################\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=50,\n",
    "                trials=trials)\n",
    "\n",
    "    print(\"Best: \", best)\n",
    "    ###################################################\n",
    "\n",
    "    from xgboost import XGBClassifier\n",
    "    XGBmodel = XGBClassifier(n_estimators = best['n_estimators'],\n",
    "                                max_depth = best['max_depth'],\n",
    "                                learning_rate = best['learning_rate'],\n",
    "                                gamma = best['gamma'],\n",
    "                                min_child_weight = best['min_child_weight'],\n",
    "                                subsample = best['subsample'],\n",
    "                                colsample_bytree = best['colsample_bytree']\n",
    "                                )\n",
    "\n",
    "    XGBmodel.fit(X_train, y_train)\n",
    "\n",
    "    # Applying k-Fold Cross Validation\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    accuracies = cross_val_score(estimator = XGBmodel, X = X_train, y = y_train, cv = 10)\n",
    "    CrossValMean = accuracies.mean()\n",
    "    print(\"Final CrossValMean: \", CrossValMean)\n",
    "\n",
    "    CrossValSTD = accuracies.std()\n",
    "    y_pred = XGBmodel.predict(X_test)\n",
    "    \n",
    "#     draw_cm(y_test, y_pred)\n",
    "    acc_nb = round(metrics.accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "    print('Total Accuracy: ', acc_nb )\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print('Confusion Matrix\\n')\n",
    "    print(confusion)\n",
    "\n",
    "    #importing accuracy_score, precision_score, recall_score, f1_score\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "    print('Micro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='micro')))\n",
    "    print('Micro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='micro')))\n",
    "    print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='micro')))\n",
    "\n",
    "    print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "    print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "    print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "    \n",
    "    print('Macro Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='macro')))\n",
    "    print('Macro Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='macro')))\n",
    "    print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_test, y_pred, average='macro')))\n",
    "\n",
    "    print('Weighted Precision: {:.2f}'.format(precision_score(y_test, y_pred, average='weighted')))\n",
    "    print('Weighted Recall: {:.2f}'.format(recall_score(y_test, y_pred, average='weighted')))\n",
    "    print('Weighted F1-score: {:.2f}'.format(f1_score(y_test, y_pred, average='weighted')))\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print('\\nClassification Report\\n')\n",
    "    print(classification_report(y_test, y_pred, target_names=['Class 1', 'Class 2', 'Class 3', 'Class 4']))\n",
    "\n",
    "    \n",
    "#     results = Modeltest(X_test, y_test, y_pred, XGBmodel, 'XGBoost hyperopt', SVM = False)\n",
    "    \n",
    "    return XGBmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBmodel = fast_boost(X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
